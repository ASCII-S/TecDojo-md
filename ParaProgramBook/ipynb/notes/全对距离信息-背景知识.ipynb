{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a603002",
   "metadata": {},
   "source": [
    "[[第 4 章 c++多线程编程]]\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f4f369",
   "metadata": {},
   "source": [
    "### **传统距离度量**\n",
    "\n",
    "1. **欧几里得距离 (Euclidean Distance)**:\n",
    "    - 定义：计算两个点之间的直线距离。公式为：  \n",
    "        $d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n",
    "    - 特点：适用于连续数值型数据，常用于图像处理和几何计算。\n",
    "2. **曼哈顿距离 (Manhattan Distance)**:\n",
    "    - 定义：计算两个点在各坐标轴上的绝对差的总和。公式为：  \n",
    "        $d(x,y)=∣x1​−x2​∣+∣y1​−y2​∣$  \n",
    "        $d(x, y) = \\sum_{i=1}^{n} |x_i - y_i|$\n",
    "    - 特点：适用于有明确坐标的离散数据，尤其在城市街道布局中常用（如通过网格行走）。\n",
    "3. 切比雪夫距离（Chebyshev distance），\n",
    "    \n",
    "    - 定义: 也称为棋盘距离定义为在一个 n 维空间中两个点之间的最大绝对坐标差。\n",
    "    - 公式: 对于两个点 $(x1,y1,…,xn)$和 $(x2,y2,…,xn)$，切比雪夫距离的公式为：\n",
    "        \n",
    "        $d(x,y)=max⁡(∣x1−x2∣,∣y1−y2∣,…,∣xn−yn∣)$\n",
    "        \n",
    "    \n",
    "    这意味着在任意两个点之间，移动的距离由在任一维度上的最大移动距离决定。\n",
    "    \n",
    "\n",
    "### **相似度度量**\n",
    "\n",
    "1. **内积 (Dot Product)**:\n",
    "    - 定义：两个向量的内积可以用来衡量它们的相似度，尤其在向量空间模型中。公式为：\n",
    "        \n",
    "        $\\text{dot}(x, y) = \\sum_{i=1}^{n} x_i \\cdot y_i$\n",
    "        \n",
    "    - 特点：在高维空间中，内积可以用于判断向量方向的相似性。\n",
    "2. **相关性度量**:\n",
    "    - **Pearson 相关系数**：衡量两个变量之间线性关系的强度，值域在-1到1之间，值越接近1或-1，线性关系越强。\n",
    "    - **Spearman 相关系数**：衡量两个变量的单调关系，基于排序数据，适用于非线性关系。\n",
    "3. **互信息 (Mutual Information)**:\n",
    "    - 定义：衡量两个随机变量之间的信息共享程度，反映了一个变量对另一个变量的依赖程度。  \n",
    "        $I(X; Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log \\left( \\frac{p(x, y)}{p(x)p(y)} \\right)$\n",
    "    - 特点：可用于评估特征选择和聚类任务中的变量之间的关系。\n",
    "\n",
    "# SVM\n",
    "\n",
    "支持向量机（Support Vector Machine，SVM）是一种监督学习模型，广泛用于分类和回归分析。SVM的核心思想是找到一个最优超平面（hyperplane），将不同类别的数据点分开，并最大化这个超平面到最近样本点的间隔（margin）。\n",
    "\n",
    "### SVM的基本概念：\n",
    "\n",
    "1. **超平面**：在特征空间中，超平面是一个将数据分开的平面（在二维空间中是直线，在三维空间中是平面）。SVM旨在寻找一个能最好地将不同类别分开的超平面。\n",
    "2. **支持向量**：在SVM中，最重要的数据点是“支持向量”，即位于决策边界附近的点。支持向量直接影响到超平面的位置和方向。\n",
    "3. **最大化间隔**：SVM的目标是最大化支持向量与超平面之间的间隔，使得分类的鲁棒性更强。\n",
    "4. **核函数**：SVM可以通过核技巧（kernel trick）将数据映射到更高维的空间，以便在这个空间中找到线性可分的超平面。常用的核函数包括线性核、多项式核和高斯核（RBF）。\n",
    "    - **线性核**：是最简单的核函数，形式为 _$K(xi,xj)=⟨xi,xj⟩$_，其中$⟨⋅,⋅⟩$表示内积。线性核适用于线性可分的情况。\n",
    "    - **径向基函数核**（Radial Basis Function, RBF）：形式为 _$K(xi,xj)=exp(−γ∥xi−xj∥2)$_，其中$γ$是一个参数，控制核函数的宽度。RBF核适用于非线性可分的数据。\n",
    "    - **全对距离信息**：指的是在计算距离或相似度时使用的所有数据点之间的距离。许多应用（如聚类、分类等）依赖于这种距离信息，以便更好地理解数据的结构和分布。\n",
    "\n",
    "### SVM的工作流程：\n",
    "\n",
    "1. **选择特征**：选择适合的特征来描述数据点。\n",
    "2. **选择合适的核函数**：根据数据的分布选择合适的核函数，以便将数据映射到高维空间。\n",
    "3. **训练模型**：使用训练数据集训练SVM模型，寻找最优超平面。\n",
    "4. **预测**：使用训练好的模型对新样本进行分类或回归。\n",
    "\n",
    "### 优点与缺点：\n",
    "\n",
    "- **优点**：\n",
    "    - 在高维空间中表现良好，适用于复杂的决策边界。\n",
    "    - 对小样本高维数据集有效，且具有较好的泛化能力。\n",
    "    - 能够使用不同的核函数处理非线性问题。\n",
    "- **缺点**：\n",
    "    - 训练时间较长，尤其是在大规模数据集上。\n",
    "    - 对于噪声和重叠类别的样本敏感。\n",
    "    - 参数选择和核函数的选择对性能有较大影响。\n",
    "\n",
    "SVM广泛应用于图像分类、文本分类和生物信息学等领域。\n",
    "\n",
    "[[第 4 章 c++多线程编程]]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
