{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a67da5e",
   "metadata": {},
   "source": [
    "[[第 9.0 章 MPI入门]]\n",
    "\n",
    "---\n",
    "\n",
    "在并行计算中，集体通信是多个进程之间协同数据交换的重要机制。MPI 提供了多种集体通信操作，用于高效地在所有或部分进程之间分发、收集或规约数据。\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 集体通信的基本概念\n",
    "\n",
    "- **全体进程参与**：集体通信操作必须由通信域内的所有进程调用。\n",
    "- **同步或半同步**：集体通信通常会同步参与的进程，确保数据一致性。\n",
    "- **隐式拓扑结构**：通过通信域组织进程（如树形结构或环形结构）。\n",
    "\n",
    "---\n",
    "\n",
    "## 3.2 常见的集体通信操作\n",
    "\n",
    "1. **广播（**`**MPI_Bcast**`**）**\n",
    "    \n",
    "    将数据从一个进程发送到所有其他进程。\n",
    "    \n",
    "2. **收集（**`**MPI_Gather**` **和** `**MPI_Allgather**`**）**\n",
    "    \n",
    "    从所有进程收集数据到一个或所有进程。\n",
    "    \n",
    "3. **分散（**`**MPI_Scatter**`**）**\n",
    "    \n",
    "    从一个进程向所有其他进程分发数据。\n",
    "    \n",
    "4. **规约（**`**MPI_Reduce**` **和** `**MPI_Allreduce**`**）**\n",
    "    \n",
    "    将所有进程的数据进行规约操作（如求和、最大值）。\n",
    "    \n",
    "5. **屏障同步（**`**MPI_Barrier**`**）**\n",
    "    \n",
    "    使所有进程同步，确保它们在同一时间点继续执行。\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "## 3.3 每个操作的函数原型与示例\n",
    "\n",
    "### 3.3.1 广播（`MPI_Bcast`）\n",
    "\n",
    "函数原型\n",
    "\n",
    "```C\n",
    "int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm);\n",
    "```\n",
    "\n",
    "- **参数**：\n",
    "    - `buffer`：广播的数据缓冲区（发送或接收）。\n",
    "    - `count`：数据元素的数量。\n",
    "    - `datatype`：数据类型（如 `MPI_INT`）。\n",
    "    - `root`：广播数据的源进程编号。\n",
    "    - `comm`：通信域。\n",
    "\n",
    "示例代码\n",
    "\n",
    "```C\n",
    "\\#include <mpi.h>\n",
    "\\#include <stdio.h>\n",
    "int main(int argc, char *argv[]) {\n",
    "    int rank, data = 0;\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        data = 42;  // Root 进程初始化数据\n",
    "    }\n",
    "\n",
    "    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    printf(\"Rank %d received data %d\\n\", rank, data);\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3.2 收集（`MPI_Gather`）\n",
    "\n",
    "函数原型\n",
    "\n",
    "```C\n",
    "int MPI_Gather(const void *sendbuf, int sendcount, MPI_Datatype sendtype,\n",
    "               void *recvbuf, int recvcount, MPI_Datatype recvtype,\n",
    "               int root, MPI_Comm comm);\n",
    "\n",
    "```\n",
    "\n",
    "- **参数**：\n",
    "    - `sendbuf`：每个进程发送的数据缓冲区。\n",
    "    - `sendcount`：每个进程发送的数据元素数量。\n",
    "    - `sendtype`：发送数据类型。\n",
    "    - `recvbuf`：接收所有数据的缓冲区（仅 root 进程）。\n",
    "    - `recvcount`：每个进程接收的数据元素数量。\n",
    "    - `recvtype`：接收数据类型。\n",
    "    - `root`：接收数据的目标进程编号。\n",
    "    - `comm`：通信域。\n",
    "\n",
    "示例代码\n",
    "\n",
    "```C\n",
    "\\#include <mpi.h>\n",
    "\\#include <stdio.h>\n",
    "int main(int argc, char *argv[]) {\n",
    "    int rank, size, send_data, recv_data[4];\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    send_data = rank + 1;  // 每个进程的数据\n",
    "\n",
    "    MPI_Gather(&send_data, 1, MPI_INT, recv_data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        printf(\"Rank 0 gathered data: \");\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            printf(\"%d \", recv_data[i]);\n",
    "            //MPI_Gather 会将所有 rank 的 send_data 数据汇集到 root 的 recv_data 中。\n",
    "            //对于非 root 的进程，recv_data 参数在调用 MPI_Gather 时是 无意义的，即使分配了空间，也不会被 MPI 填充任何内容。\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3.3 规约（`MPI_Reduce`）\n",
    "\n",
    "函数原型\n",
    "\n",
    "```C\n",
    "int MPI_Reduce(const void *sendbuf, void *recvbuf, int count, MPI_Datatype datatype,\n",
    "               MPI_Op op, int root, MPI_Comm comm);\n",
    "```\n",
    "\n",
    "- **参数**：\n",
    "    - `sendbuf`：每个进程发送的数据缓冲区。\n",
    "    - `recvbuf`：存储规约结果的缓冲区（仅 root 进程）。\n",
    "    - `count`：规约的数据元素数量。\n",
    "    - `datatype`：数据类型。\n",
    "    - `op`：规约操作（如 `MPI_SUM`）。\n",
    "        \n",
    "        |   |   |\n",
    "        |---|---|\n",
    "        |操作符|描述|\n",
    "        |`**MPI_MAX**`|计算所有元素的最大值。|\n",
    "        |`**MPI_MIN**`|计算所有元素的最小值。|\n",
    "        |`**MPI_SUM**`|计算所有元素的和。|\n",
    "        |`**MPI_PROD**`|计算所有元素的积。|\n",
    "        |`**MPI_LAND**`|按位逻辑与（`AND`）。|\n",
    "        |`**MPI_BAND**`|按位与（`bitwise AND`）。|\n",
    "        |`**MPI_LOR**`|按位逻辑或（`OR`）。|\n",
    "        |`**MPI_BOR**`|按位或（`bitwise OR`）。|\n",
    "        |`**MPI_LXOR**`|按位逻辑异或（`XOR`）。|\n",
    "        |`**MPI_BXOR**`|按位异或（`bitwise XOR`）。|\n",
    "        |`**MPI_MAXLOC**`|查找最大值及其对应的进程 rank。|\n",
    "        |`**MPI_MINLOC**`|查找最小值及其对应的进程 rank。|\n",
    "        \n",
    "    - `root`：接收结果的目标进程编号。\n",
    "    - `comm`：通信域。\n",
    "\n",
    "示例代码\n",
    "\n",
    "```C\n",
    "\\#include <mpi.h>\n",
    "\\#include <stdio.h>\n",
    "int main(int argc, char *argv[]) {\n",
    "    int rank, size, send_data, result;\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "\n",
    "    send_data = rank + 1;  // 每个进程的数据\n",
    "\n",
    "    MPI_Reduce(&send_data, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        printf(\"Sum of all ranks: %d\\n\", result);\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3.4 屏障同步（`MPI_Barrier`）\n",
    "\n",
    "函数原型\n",
    "\n",
    "```C\n",
    "int MPI_Barrier(MPI_Comm comm);\n",
    "```\n",
    "\n",
    "- **参数**：\n",
    "    - `comm`：通信域。\n",
    "\n",
    "示例代码\n",
    "\n",
    "```C\n",
    "\\#include <mpi.h>\n",
    "\\#include <stdio.h>\n",
    "\\#include <unistd.h> // for sleep\n",
    "int main(int argc, char *argv[]) {\n",
    "    int rank;\n",
    "    int size;\n",
    "    char recv_msgs[50][50];\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
    "    \n",
    "    //由于直接使用printf的缓冲模式,会导致无法看出进程顺序,因此这里采用将所有进程的输出都归并到0进程中,保证顺序再打印出来\n",
    "    char msg[50];\n",
    "    sprintf(msg, \"Rank %d reached the barrier.\\n\", rank);\n",
    "    MPI_Gather(msg, 50, MPI_CHAR, recv_msgs, 50, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            printf(\"%s\", recv_msgs[i]);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    MPI_Barrier(MPI_COMM_WORLD);\n",
    "\n",
    "    sprintf(msg, \"Rank %d passed the barrier.\\n\", rank);\n",
    "    MPI_Gather(msg, 50, MPI_CHAR, recv_msgs, 50, MPI_CHAR, 0, MPI_COMM_WORLD);\n",
    "\n",
    "    if (rank == 0) {\n",
    "        for (int i = 0; i < size; i++) {\n",
    "            printf(\"%s\", recv_msgs[i]);\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
