{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac04e75",
   "metadata": {},
   "source": [
    "[[并行程序设计]]\n",
    "\n",
    "---\n",
    "\n",
    "# # pragma omp制导语句\n",
    "\n",
    "[[基本用法]]\n",
    "\n",
    "## 向量加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955a690",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>\n",
    "\\#include <cstdint>\n",
    "\\#include <vector>\n",
    "\\#include \"../include/hpc_helpers.hpp\" // 包含 TIMERSTART 和 TIMERSTOP，以及 no_init_t 模板\n",
    "\n",
    "int main() {\n",
    "    // 定义输入向量大小\n",
    "    const uint64_t num_entries = 1UL << 30;\n",
    "\n",
    "    // 使用 no_init_t 包装分配内存\n",
    "    TIMERSTART(alloc);\n",
    "    std::vector<no_init_t<uint64_t>> x(num_entries);\n",
    "    std::vector<no_init_t<uint64_t>> y(num_entries);\n",
    "    std::vector<no_init_t<uint64_t>> z(num_entries);\n",
    "    TIMERSTOP(alloc);\n",
    "\n",
    "    // 手动初始化向量 x 和 y\n",
    "    TIMERSTART(init);\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        x[i] = i;\n",
    "        y[i] = num_entries - i;\n",
    "    }\n",
    "    TIMERSTOP(init);\n",
    "\n",
    "    // 顺序计算 x + y = z\n",
    "    TIMERSTART(add_seq);\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i];\n",
    "    }\n",
    "    TIMERSTOP(add_seq);\n",
    "\n",
    "    // 并行计算 x + y = z\n",
    "    TIMERSTART(add);\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i];\n",
    "    }\n",
    "    TIMERSTOP(add);\n",
    "\n",
    "    // 检查求和结果是否正确\n",
    "    TIMERSTART(check);\n",
    "    bool is_correct = true;\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        if (z[i] != num_entries) {\n",
    "            \\#pragma omp critical\n",
    "            {\n",
    "                std::cout << \"Error at position \" << i << \", expected: \" \n",
    "                          << num_entries << \", got: \" << z[i] << std::endl;\n",
    "            }\n",
    "            is_correct = false;\n",
    "        }\n",
    "    }\n",
    "    if (is_correct) {\n",
    "        std::cout << \"All results are correct!\" << std::endl;\n",
    "    }\n",
    "    TIMERSTOP(check);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a5465",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "g++ -std=c++14 -fopenmp -O2 6.3omp_add.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5ab8d",
   "metadata": {},
   "source": [
    "**隐式同步:**\n",
    "\n",
    "**OpenMP 的** `**parallel for**`： 在一个 `**parallel for**` 块结束后，默认会隐含一个同步点，确保所有线程完成循环的所有迭代后再继续执行后续代码。\n",
    "\n",
    "**避免不必要的隐含同步**：\n",
    "\n",
    "如果可以，关闭隐含同步。例如，在 OpenMP 中使用 `**nowait**` 指令跳过隐含同步："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4fbc5",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#pragma omp parallel for nowait\n",
    "for (int i = 0; i < 10; i++) {\n",
    "    // 任务执行\n",
    "}\n",
    "// 不等待循环完成，直接继续执行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c6435",
   "metadata": {},
   "source": [
    "## 矩阵向量乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2eb27",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>\n",
    "\\#include <cstdint>\n",
    "\\#include <vector>\n",
    "\\#include \"../include/hpc_helpers.hpp\" // 包含 TIMERSTART, TIMERSTOP 和 no_init_t 模板\n",
    "\n",
    "// 初始化矩阵 A 和向量 x\n",
    "template <typename value_t, typename index_t>\n",
    "void init(std::vector<value_t>& A, std::vector<value_t>& x, index_t m, index_t n) {\n",
    "    for (index_t row = 0; row < m; row++) {\n",
    "        for (index_t col = 0; col < n; col++) {\n",
    "            A[row * n + col] = (row >= col) ? 1 : 0; // 下三角矩阵\n",
    "        }\n",
    "    }\n",
    "    for (index_t col = 0; col < n; col++) {\n",
    "        x[col] = col; // 初始化 x 为连续值\n",
    "    }\n",
    "}\n",
    "\n",
    "// 矩阵向量乘法\n",
    "template <typename value_t, typename index_t>\n",
    "void mult(std::vector<value_t>& A, std::vector<value_t>& x, std::vector<value_t>& b, index_t m, index_t n, bool parallel) {\n",
    "    \\#pragma omp parallel for if (parallel)\n",
    "    for (index_t row = 0; row < m; row++) {\n",
    "        value_t accum = value_t(0);\n",
    "        for (index_t col = 0; col < n; col++) {\n",
    "            accum += A[row * n + col] * x[col];\n",
    "        }\n",
    "        b[row] = accum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const uint64_t n = 1UL << 15; // 矩阵列数\n",
    "    const uint64_t m = 1UL << 15; // 矩阵行数\n",
    "\n",
    "    TIMERSTART(overall);\n",
    "\n",
    "    // 分配向量和矩阵的内存\n",
    "    TIMERSTART(alloc);\n",
    "    std::vector<no_init_t<uint64_t>> A(m * n); // 矩阵 A\n",
    "    std::vector<no_init_t<uint64_t>> x(n);     // 向量 x\n",
    "    std::vector<no_init_t<uint64_t>> b(m);     // 结果向量 b\n",
    "    TIMERSTOP(alloc);\n",
    "\n",
    "    // 初始化矩阵 A 和向量 x\n",
    "    TIMERSTART(init);\n",
    "    init(A, x, m, n);\n",
    "    TIMERSTOP(init);\n",
    "\n",
    "    // 顺序计算 A * x = b 三次\n",
    "    for (uint64_t k = 0; k < 3; k++) {\n",
    "        TIMERSTART(mult_seq);\n",
    "        mult(A, x, b, m, n, false); // 串行计算\n",
    "        TIMERSTOP(mult_seq);\n",
    "    }\n",
    "\n",
    "    // 并行计算 A * x = b 三次\n",
    "    for (uint64_t k = 0; k < 3; k++) {\n",
    "        TIMERSTART(mult_par);\n",
    "        mult(A, x, b, m, n, true); // 并行计算\n",
    "        TIMERSTOP(mult_par);\n",
    "    }\n",
    "\n",
    "    TIMERSTOP(overall);\n",
    "\n",
    "    // 验证结果\n",
    "    for (uint64_t index = 0; index < m; index++) {\n",
    "        if (b[index] != index * (index + 1) / 2) {\n",
    "            std::cout << \"Error at position \" << index\n",
    "                      << \", value: \" << b[index] << std::endl;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6992d",
   "metadata": {},
   "source": [
    "# 基本并行归约\n",
    "\n",
    "## 最近邻分类\n",
    "\n",
    "最近邻分类是一种简单而直观的**监督学习**算法，用于分类问题。其基本思想是：**给定一个待分类样本，根据其与训练集中样本的距离，选择最近的一个或多个样本的类别进行预测**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b661bd",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>       // for std::cout\n",
    "\\#include <limits>         // for std::numeric_limits\n",
    "\\#include <vector>         // for std::vector\n",
    "\\#include \"../include/hpc_helpers.hpp\"  // for TIMERSTART and TIMERSTOP\n",
    "\\#include \"../include/binary-IO.hpp\"    // for load_binary function\n",
    "\n",
    "// 计算全对距离（all-vs-all distance）\n",
    "template <typename value_t, typename index_t>\n",
    "void all_vs_all(value_t* test, value_t* train, value_t* delta, \n",
    "                index_t num_test, index_t num_train, index_t num_features, \n",
    "                bool parallel) {\n",
    "    \\#pragma omp parallel for collapse(2) if (parallel)\n",
    "    for (index_t i = 0; i < num_test; i++) {\n",
    "        for (index_t j = 0; j < num_train; j++) {\n",
    "            value_t accum = value_t(0); // 累加器\n",
    "            for (index_t k = 0; k < num_features; k++) {\n",
    "                const value_t residue = test[i * num_features + k] \n",
    "                                      - train[j * num_features + k];\n",
    "                accum += residue * residue; // 计算欧几里得距离平方\n",
    "            }\n",
    "            delta[i * num_train + j] = accum; // 存储结果\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fda5ba",
   "metadata": {},
   "source": [
    "`**collapse(2)**` **的含义**\n",
    "\n",
    "在 OpenMP 中，`**collapse(2)**` 是一个**修饰符**，用于告诉编译器将**两层嵌套循环**合并成一个循环，并进行并行化。这有助于提高多线程的效率，尤其是在处理多维循环时。\n",
    "\n",
    "**优点**\n",
    "\n",
    "1. **提高并行效率**：\n",
    "    - 在外层循环迭代次数较少时（例如 _N_ 很小），单独对外层循环进行并行化可能无法充分利用线程。\n",
    "2. **均匀负载分配**：\n",
    "    - 通过将多层循环展开为一个单层循环，任务可以更均匀地分配给多个线程，减少负载不均的问题。\n",
    "\n",
    "**使用限制**\n",
    "\n",
    "1. **循环必须是规整的（rectangular loops）**：\n",
    "    - 每层循环的范围必须是已知的固定值。\n",
    "2. **可能增加开销**：\n",
    "    - 当循环体中的计算量很小，线程切换的开销可能抵消并行化的优势。\n",
    "\n",
    "**细粒度优化:**\n",
    "\n",
    "适合外层循环少(减少创建线程池次数),内层循环计算任务多(并行后加速效果大)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31901e3",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "value_t accum = value_t(0); // 累加器\n",
    "\n",
    "for (index_t k = 0; k < num_features; k++) {\n",
    "    accum += some_value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e6a0c",
   "metadata": {},
   "source": [
    "**产生的问题: accum的在多个线程中的竞争问题**\n",
    "\n",
    "**解决策略:**\n",
    "\n",
    "1. 把accum设置成原子结构: 开销很大\n",
    "2. 用锁机制: 开销很大\n",
    "3. 最有效的方法:`#pragma omp parallel for reduction(+:accum)`\n",
    "    \n",
    "    OpenMP 提供了 `**reduction**` 指令，用于在多个线程之间安全地累加变量。`**reduction**` 会为每个线程创建一个 `**accum**` 的私有副本，线程完成计算后将结果合并到全局变量中。\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "## 并行标签预测\n",
    "\n",
    "**1. 完全配对的距离矩阵**\n",
    "\n",
    "我们之前通过计算每个测试样本和每个训练样本之间的距离，得到了一个完全配对的距离矩阵 D_D_。矩阵的形状为：num_test×num_train\n",
    "\n",
    "- 每行对应一个测试样本与所有训练样本之间的距离。\n",
    "- 每列对应一个训练样本与所有测试样本之间的距离。\n",
    "\n",
    "通过扫描矩阵 D_D_ 的每一行，可以找到与测试样本最接近的训练样本（即最小距离值对应的索引）。\n",
    "\n",
    "**2. 使用独热编码的标签**\n",
    "\n",
    "独热编码是一种常见的分类标签表示方式，每个类别用一个长度为 C_C_的二进制向量表示，其中 C是类别总数：\n",
    "\n",
    "- 只有一个位置为 1，其他位置为 0。\n",
    "- 例如，在 MNIST 数据集中，数字 3 的标签用 (0,0,0,1,0,0,0,0,0,0) 表示。\n",
    "\n",
    "**3. 分类器准确性的计算**\n",
    "\n",
    "分类准确性（accuracy）是一个常见的分类器性能指标，定义如下：\n",
    "\n",
    "Accuracy=$\\frac{正确分类的样本数量测试集中样本总数}{测试集中样本总数正确分类的样本数量}$\n",
    "\n",
    "计算过程：\n",
    "\n",
    "1. 比较每个测试样本的预测标签 和真实标签。\n",
    "2. 统计预测正确的样本数量。\n",
    "3. 用正确分类的样本数量除以测试集的总样本数，得到分类准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a9de5",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "template <typename label_t, typename value_t, typename index_t>\n",
    "value_t accuracy(\n",
    "    const label_t* label_test,\n",
    "    const label_t* label_train,\n",
    "    const value_t* delta,\n",
    "    index_t num_test,\n",
    "    index_t num_train,\n",
    "    index_t num_classes,\n",
    "    bool parallel\n",
    ") {\n",
    "    index_t counter = 0;\n",
    "\n",
    "    \\#pragma omp parallel for reduction(+:counter) if (parallel)\n",
    "    for (index_t i = 0; i < num_test; i++) {\n",
    "        value_t bsf = std::numeric_limits<value_t>::max(); // 初始化最近距离\n",
    "        index_t jst = std::numeric_limits<index_t>::max(); // 最近邻索引初始化\n",
    "\n",
    "        // 找到最近邻\n",
    "        for (index_t j = 0; j < num_train; j++) {\n",
    "            const value_t value = delta[i * num_train + j];\n",
    "            if (value < bsf) {\n",
    "                bsf = value;\n",
    "                jst = j;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // 比较标签\n",
    "        bool match = true;\n",
    "        for (index_t k = 0; k < num_classes; k++) {\n",
    "            match &&= label_test[i * num_classes + k] == label_train[jst * num_classes + k];\n",
    "        }\n",
    "\n",
    "        counter += match; // 如果匹配，计数器加 1\n",
    "    }\n",
    "\n",
    "    return value_t(counter) / value_t(num_test); // 返回分类准确性\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252316ae",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "int main(int argc, char* argv[]) {\n",
    "    // 是否并行执行\n",
    "    const bool parallel = argc > 1;\n",
    "    std::cout << \"running \" << (parallel ? \"in parallel\" : \"sequentially\") << std::endl;\n",
    "\n",
    "    // 数据维度定义\n",
    "    const uint64_t num_features = 28 * 28;\n",
    "    const uint64_t num_classes = 10;\n",
    "    const uint64_t num_entries = 65000;\n",
    "    const uint64_t num_train = 55000;\n",
    "    const uint64_t num_test = num_entries - num_train;\n",
    "\n",
    "    // 数据分配\n",
    "    std::vector<float> input(num_entries * num_features);  // 图像数据\n",
    "    std::vector<float> label(num_entries * num_classes);   // 标签数据\n",
    "    std::vector<float> delta(num_test * num_train);        // 距离矩阵\n",
    "\n",
    "    // 从磁盘加载数据\n",
    "    load_binary(input.data(), input.size(), \"./data/X.bin\");\n",
    "    load_binary(label.data(), label.size(), \"./data/Y.bin\");\n",
    "\n",
    "    // 计算全对距离矩阵\n",
    "    TIMERSTART(all_vs_all);\n",
    "    const uint64_t inp_off = num_train * num_features;\n",
    "    all_vs_all(\n",
    "        input.data() + inp_off,   // 测试集数据\n",
    "        input.data(),             // 训练集数据\n",
    "        delta.data(),             // 距离矩阵\n",
    "        num_test, num_train,      // 测试集和训练集大小\n",
    "        num_features, parallel    // 是否并行\n",
    "    );\n",
    "    TIMERSTOP(all_vs_all);\n",
    "\n",
    "    // 分类并计算准确率\n",
    "    TIMERSTART(classify);\n",
    "    const uint64_t lbl_off = num_train * num_classes;\n",
    "    auto acc = accuracy(\n",
    "        label.data() + lbl_off,   // 测试集标签\n",
    "        label.data(),             // 训练集标签\n",
    "        delta.data(),             // 距离矩阵\n",
    "        num_test, num_train,      // 测试集和训练集大小\n",
    "        num_classes, parallel     // 是否并行\n",
    "    );\n",
    "    TIMERSTOP(classify);\n",
    "\n",
    "    // 输出准确率\n",
    "    std::cout << \"test accuracy: \" << acc << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ab60d",
   "metadata": {},
   "source": [
    "全部程序由6.5+6.6+6.7组成\n",
    "\n",
    "---\n",
    "\n",
    "# 不平衡循环调度\n",
    "\n",
    "## 负载失衡问题引入\n",
    "\n",
    "问题引入:计算矩阵内积是常用的计算方式, 这种计算的特点是沿主对角线呈对称形式,因此在计算时只要计算下/上三角即可. 对于计算矩阵内积,简单在外层使用omp制导语句会导致负载失衡,一些线程比其他线程计算更多的元素值.\n",
    "\n",
    "## OpenMP的guided调度模式\n",
    "\n",
    "在 OpenMP 中，调度模式决定了如何将循环的迭代任务分配给线程。调度的目标是实现线程负载平衡和性能优化。\n",
    "\n",
    "|   |   |   |   |   |\n",
    "|---|---|---|---|---|\n",
    "|**模式**|**分配方式**|**默认块大小**|**空闲发生场景**|**适用场景**|\n",
    "|**static**|固定大小块，循环分配|n/p|如果线程完成任务早，需等待其他线程完成|均匀任务分布，工作量相等|\n",
    "|**dynamic**|动态分配，线程空闲时获取新任务|1|仅在最后一个块任务时可能空闲|不均匀任务分布，工作量差异较大|\n",
    "|**guided**|动态分配，块大小递减|n/p|同动态调度|初始任务多，后期任务少|\n",
    "|**auto**|编译器或运行时决定|−−|依赖编译器行为|不确定任务特性，依赖系统优化|\n",
    "|**runtime**|通过 `**OMP_SCHEDULE**` 决定|−−|取决于运行时设定|灵活配置调试，运行时可更改模式|\n",
    "\n",
    "---\n",
    "\n",
    "### **静态调度 (static)**\n",
    "\n",
    "- **特点**：\n",
    "    - 将n次迭代分成 n/c个**固定大小的块**，每个块包含 _c_ 次迭代。\n",
    "    - 按照循环方式（循环块分配），将块分配给线程组。\n",
    "    - **默认块大小**：\n",
    "        - 如果未指定块大小 _c_，则块大小为总迭代次数 _n_ 除以线程数 _p_（即纯块分配）。\n",
    "    - **线程状态**：\n",
    "        - 如果一个线程完成了其分配的任务，它将处于**空闲等待**状态，直到所有线程完成工作。\n",
    "- **适用场景**：任务分布均匀，迭代工作量相等。\n",
    "\n",
    "---\n",
    "\n",
    "### **动态调度 (dynamic)**\n",
    "\n",
    "- **特点**：\n",
    "    - 迭代也分为块，但块任务是动态分配的，即每次将下一个块分配给空闲线程。\n",
    "    - 动态调度避免了线程空闲，因为线程完成后可以立即获取新任务。\n",
    "    - **默认块大小**：如果未指定块大小，默认大小为 1（即纯循环分配）。块大小为c时,表示为线程一次分配连续的c个迭代任务.\n",
    "- **线程状态**：\n",
    "    - 除非一个线程执行的是最后一个任务块，否则不会出现空闲。\n",
    "- **适用场景**：\n",
    "    \n",
    "    任务分布不均，工作量差异较大，需要动态负载平衡。\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "### **引导调度 (guided)**\n",
    "\n",
    "- **特点**：\n",
    "    - 块大小以递减方式分配：开始时较大，随着任务的进行逐渐变小。\n",
    "    - 动态分配线程执行块，类似动态调度。\n",
    "    - **默认块大小**：初始块大小等于总迭代次数，最小块大小默认为 1。\n",
    "- **线程状态**：\n",
    "    - 同动态调度，线程尽量保持忙碌。\n",
    "- **适用场景**：\n",
    "    \n",
    "    当任务分布不均，但前期任务更多、后期任务减少时（例如指数递减工作量）\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "### **自动调度 (auto)**\n",
    "\n",
    "- **特点**：\n",
    "    - 由编译器或运行时系统决定使用哪种调度模式。\n",
    "    - 允许编译器根据工作量和硬件架构自动选择最优的调度方式。\n",
    "- **适用场景**：\n",
    "    \n",
    "    不需要手动干预调度模式，依赖编译器进行优化。\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "### **运行时调度 (runtime)**\n",
    "\n",
    "- **特点**：\n",
    "    - 调度模式由环境变量 `**OMP_SCHEDULE**` 决定。\n",
    "    - 运行时选择的模式可以是上述模式之一。\n",
    "- **适用场景**：\n",
    "    \n",
    "    调试或灵活设置时有用，通过运行时环境变量控制调度行为。\n",
    "    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a2955",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream> // std::cout\n",
    "\\#include <vector>   // std::vector\n",
    "\\#include <omp.h>    // OpenMP for parallelism\n",
    "\\#include \"../include/hpc_helpers.hpp\" // TIMERSTART and TIMERSTOP macros\n",
    "\\#include \"../include/binary_IO.hpp\"   // load_binary function\n",
    "\n",
    "// Define the scheduling mode (can be modified)\n",
    "\\#define MODE static\n",
    "\\#define MODE static ,1 \n",
    "\\#define MODE static ,32\n",
    "\\#define MODE dynamic \n",
    "\\#define MODE dynamic , 32\n",
    "\n",
    "\n",
    "// Function to compute the inner product (symmetric matrix computation)\n",
    "template <typename value_t, typename index_t>\n",
    "void inner_product(value_t* data, value_t* delta, index_t num_entries, index_t num_features, bool parallel) {\n",
    "    \\#pragma omp parallel for schedule(MODE) if (parallel)\n",
    "    for (index_t i = 0; i < num_entries; i++) {\n",
    "        for (index_t j = i; j < num_entries; j++) { // Upper triangle of the matrix\n",
    "            value_t accum = value_t(0); // Initialize accumulator\n",
    "            for (index_t k = 0; k < num_features; k++) {\n",
    "                accum += data[i * num_features + k] * data[j * num_features + k];\n",
    "            }\n",
    "            // Fill both upper and lower triangle due to symmetry\n",
    "            delta[i * num_entries + j] = accum;\n",
    "            delta[j * num_entries + i] = accum;\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e94f3",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "int main(int argc, char* argv[]) {\n",
    "    // 如果有任何命令行参数，则以并行方式运行\n",
    "    const bool parallel = argc > 1;\n",
    "    std::cout << \"Running \" << (parallel ? \"in parallel\" : \"sequentially\") << std::endl;\n",
    "\n",
    "    // 定义数据矩阵的维度\n",
    "    const uint64_t num_features = 28 * 28; // 每个样本的特征数\n",
    "    const uint64_t num_entries = 65000;    // 样本总数\n",
    "\n",
    "    // 分配内存\n",
    "    TIMERSTART(alloc)\n",
    "    std::vector<float> input(num_entries * num_features); // 输入数据矩阵\n",
    "    std::vector<float> delta(num_entries * num_entries);  // 内积矩阵\n",
    "    TIMERSTOP(alloc)\n",
    "\n",
    "    // 从磁盘读取数据\n",
    "    TIMERSTART(read_data)\n",
    "    load_binary(input.data(), input.size(), \"./data/X.bin\");\n",
    "    TIMERSTOP(read_data)\n",
    "\n",
    "    // 计算内积矩阵\n",
    "    TIMERSTART(inner_product)\n",
    "    inner_product(input.data(), delta.data(), num_entries, num_features, parallel);\n",
    "    TIMERSTOP(inner_product)\n",
    "\n",
    "    std::cout << \"Inner product computation complete!\" << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f51a7",
   "metadata": {},
   "source": [
    "# 高级归约\n",
    "\n",
    "## MNIST 数据集上的 SOFTMAX 回归分类器\n",
    "\n",
    "### 预测阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3b9f5",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include \"./include/hpc_helpers.hpp\"  // timers\n",
    "\\#include \"./include/binary-IO.hpp\"     // load images\n",
    "\\#include <limits>\n",
    "\\#include <vector>\n",
    "\\#include <cmath>\n",
    "\\#include <algorithm> // For std::max\n",
    "\n",
    "// Numerical limits of data types\n",
    "template <typename value_t, typename index_t>\n",
    "void softmax_regression(\n",
    "    value_t* input, \n",
    "    value_t* output, \n",
    "    value_t* weights, \n",
    "    value_t* bias, \n",
    "    index_t n_input, \n",
    "    index_t n_output\n",
    ") {\n",
    "    // Step 1: Compute the weighted sum of inputs for each output class\n",
    "    for (index_t j = 0; j < n_output; j++) {\n",
    "        value_t accum = value_t(0);\n",
    "        for (index_t k = 0; k < n_input; k++) {\n",
    "            accum += weights[j * n_input + k] * input[k];  // Corrected multiplication\n",
    "        }\n",
    "        output[j] = accum + bias[j];  // Add bias to the weighted sum\n",
    "    }\n",
    "\n",
    "    // Step 2: Find the maximum value in the output (for numerical stability)\n",
    "    value_t mu = std::numeric_limits<value_t>::lowest(); // Initialize to the lowest possible value\n",
    "    for (index_t index = 0; index < n_output; index++) {\n",
    "        mu = std::max(mu, output[index]);\n",
    "    }\n",
    "\n",
    "    // Step 3: Compute exp(z_j - mu) for numerical stability\n",
    "    for (index_t j = 0; j < n_output; j++) {\n",
    "        output[j] = std::exp(output[j] - mu);  // Apply exp function after subtracting mu\n",
    "    }\n",
    "\n",
    "    // Step 4: Compute the normalization factor Z = sum_j exp(z_j)\n",
    "    value_t norm = value_t(0);\n",
    "    for (index_t j = 0; j < n_output; j++) {\n",
    "        norm += output[j];  // Sum of exponentiated values\n",
    "    }\n",
    "\n",
    "    // Step 5: Normalize the output values to get probabilities\n",
    "    for (index_t j = 0; j < n_output; j++) {\n",
    "        output[j] /= norm;  // Normalize by dividing each element by the sum\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96793f49",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "template <typename value_t, typename index_t>\n",
    "index_t argmax(value_t* neurons, index_t n_units) {\n",
    "    index_t arg = 0;\n",
    "    value_t max = std::numeric_limits<value_t>::lowest();  // Initialize to lowest value\n",
    "\n",
    "    for (index_t j = 0; j < n_units; j++) {\n",
    "        const value_t val = neurons[j];\n",
    "        if (val > max) {\n",
    "            arg = j;\n",
    "            max = val;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return arg;  // Return index of the maximum value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e2464",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "template <typename value_t, typename index_t>\n",
    "value_t accuracy(\n",
    "    value_t *input,\n",
    "    value_t *label,\n",
    "    value_t *weights,\n",
    "    value_t *bias,\n",
    "    index_t num_entries,\n",
    "    index_t num_features,\n",
    "    index_t num_classes) {\n",
    "\n",
    "    index_t counter = index_t(0);\n",
    "\n",
    "    \\#pragma omp parallel for reduction(+: counter)\n",
    "    for (index_t i = 0; i < num_entries; i++) {\n",
    "        value_t output[num_classes];  // Output for each class\n",
    "\n",
    "        const uint64_t input_off = i * num_features;\n",
    "        const uint64_t label_off = i * num_classes;\n",
    "\n",
    "        // Perform softmax regression\n",
    "        softmax_regression(input + input_off, output, weights, bias, num_features, num_classes);\n",
    "\n",
    "        // Compare predicted class with the true class\n",
    "        counter += argmax(output, num_classes) == argmax(label + label_off, num_classes);\n",
    "    }\n",
    "\n",
    "    return value_t(counter) / value_t(num_entries);  // Return the accuracy as a fraction\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec291d9",
   "metadata": {},
   "source": [
    "### 训练阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434aed39",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "template <typename value_t, typename index_t>\n",
    "void train(\n",
    "    value_t *input,\n",
    "    value_t *label,\n",
    "    value_t *weights,\n",
    "    value_t *bias,\n",
    "    index_t num_entries,\n",
    "    index_t num_features,\n",
    "    index_t num_classes,\n",
    "    index_t num_iters = 32,\n",
    "    value_t epsilon = 1e-1) {\n",
    "\n",
    "    // Allocate memory for the gradients\n",
    "    value_t *grad_bias = new value_t[num_classes];\n",
    "    value_t *grad_weights = new value_t[num_features * num_classes];\n",
    "\n",
    "    // Spawn the team of threads once\n",
    "    \\#pragma omp parallel\n",
    "    for (uint64_t iter = 0; iter < num_iters; iter++) {\n",
    "        // Zero the gradients\n",
    "        \\#pragma omp single\n",
    "        for (index_t j = 0; j < num_classes; j++) {\n",
    "            grad_bias[j] = value_t(0);\n",
    "        }\n",
    "\n",
    "        \\#pragma omp for collapse(2)\n",
    "        for (index_t j = 0; j < num_classes; j++) {\n",
    "            for (index_t k = 0; k < num_features; k++) {\n",
    "                grad_weights[j * num_features + k] = value_t(0);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Compute softmax contributions\n",
    "        \\#pragma omp for reduction(+:grad_bias[0:num_classes]) reduction(+:grad_weights[0:num_classes * num_features])\n",
    "        for (index_t i = 0; i < num_entries; i++) {\n",
    "            const index_t inp_off = i * num_features;\n",
    "            const index_t out_off = i * num_classes;\n",
    "\n",
    "            // Allocate memory for output\n",
    "            value_t *output = new value_t[num_classes];\n",
    "\n",
    "            // Perform softmax regression\n",
    "            softmax_regression(input + inp_off, output, weights, bias, num_features, num_classes);\n",
    "\n",
    "            // Compute gradients for bias and weights\n",
    "            for (index_t j = 0; j < num_classes; j++) {\n",
    "                const index_t out_ind = out_off + j;\n",
    "                const value_t lbl_res = output[j] - label[out_ind];\n",
    "                grad_bias[j] += lbl_res;\n",
    "\n",
    "                const index_t wgt_off = j * num_features;\n",
    "                for (index_t k = 0; k < num_features; k++) {\n",
    "                    const index_t wgt_ind = wgt_off + k;\n",
    "                    const index_t inp_ind = inp_off + k;\n",
    "                    grad_weights[wgt_ind] += lbl_res * input[inp_ind];\n",
    "                }\n",
    "            }\n",
    "\n",
    "            // Free the output memory\n",
    "            delete[] output;\n",
    "        }\n",
    "\n",
    "        // Adjust bias vector\n",
    "        \\#pragma omp single\n",
    "        for (index_t j = 0; j < num_classes; j++) {\n",
    "            bias[j] -= epsilon * grad_bias[j] / num_entries;\n",
    "        }\n",
    "\n",
    "        // Adjust weight matrix\n",
    "        \\#pragma omp for collapse(2)\n",
    "        for (index_t j = 0; j < num_classes; j++) {\n",
    "            for (index_t k = 0; k < num_features; k++) {\n",
    "                weights[j * num_features + k] -= epsilon * grad_weights[j * num_features + k] / num_entries;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Free gradient memory\n",
    "    delete[] grad_bias;\n",
    "    delete[] grad_weights;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff129b",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "int main() {\n",
    "    const uint64_t num_features = 28 * 28; // 每个图像的特征数量 (28x28像素)\n",
    "    const uint64_t num_classes = 10;       // 分类的数量 (0-9)\n",
    "    const uint64_t num_entries = 65000;   // 数据集中的样本总数\n",
    "\n",
    "    // 初始化输入数据、标签、权重和偏置\n",
    "    std::vector<float> input(num_entries * num_features);  // 图像数据\n",
    "    std::vector<float> label(num_entries * num_classes);   // 标签数据\n",
    "    std::vector<float> weights(num_classes * num_features); // 权重矩阵\n",
    "    std::vector<float> bias(num_classes);                  // 偏置向量\n",
    "\n",
    "    // 从二进制文件加载数据\n",
    "    load_binary(input.data(), input.size(), \"./data/X.bin\");\n",
    "    load_binary(label.data(), label.size(), \"./data/Y.bin\");\n",
    "\n",
    "    // 进入训练和测试循环\n",
    "    while (true) {\n",
    "        // 训练阶段\n",
    "        TIMERSTART(training);\n",
    "        train(\n",
    "            input.data(),         // 输入数据\n",
    "            label.data(),         // 标签数据\n",
    "            weights.data(),       // 权重矩阵\n",
    "            bias.data(),          // 偏置向量\n",
    "            55000UL,              // 训练样本数量\n",
    "            num_features,         // 每个样本的特征数\n",
    "            num_classes           // 分类数\n",
    "        );\n",
    "        TIMERSTOP(training);\n",
    "\n",
    "        // 测试阶段\n",
    "        const uint64_t off_inp = 55000 * num_features;  // 测试集偏移量（从训练集后开始）\n",
    "        const uint64_t off_lbl = 55000 * num_classes;   // 标签偏移量\n",
    "\n",
    "        TIMERSTART(accuracy);\n",
    "        auto acc = accuracy(\n",
    "            input.data() + off_inp, // 测试集数据\n",
    "            label.data() + off_lbl, // 测试集标签\n",
    "            weights.data(),         // 训练后的权重\n",
    "            bias.data(),            // 训练后的偏置\n",
    "            10000UL,                // 测试样本数量\n",
    "            num_features,           // 每个样本的特征数\n",
    "            num_classes             // 分类数\n",
    "        );\n",
    "        TIMERSTOP(accuracy);\n",
    "\n",
    "        // 输出测试集的准确率\n",
    "        std::cout << \"Accuracy on test set: \" << acc << std::endl;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97037311",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 定制归约操作符\n",
    "\n",
    "### 归约操作的数学性质\n",
    "\n",
    "**结合律**\n",
    "\n",
    "结合律是指在二进制运算中，操作的顺序不会影响结果. 结合律确保在并行归约中，无论如何划分或组合计算，最终结果都不会改变。这是并行归约算法正确性的核心条件。\n",
    "\n",
    "**幺半群的性质**\n",
    "\n",
    "幺半群的定义确保归约操作适用于特定集合 M上的所有元素：\n",
    "\n",
    "1. **结合性**：运算满足结合律。\n",
    "2. **封闭性**：对于 M 中的任何两个元素，运算结果仍在 M 中。\n",
    "3. **中性元素 e**：满足 $a∘e=e∘a=a$，例如加法的中性元素是 0，乘法的中性元素是 1。\n",
    "\n",
    "当归约运算满足这些性质时，可以安全地在并行环境中执行。\n",
    "\n",
    "**扩展数组的必要性**\n",
    "\n",
    "在实际实现中，当数组长度不是 2 的幂时，为了便于采用树结构归约，我们需要将数组扩展到最近的 2 的幂次。例如：\n",
    "\n",
    "- 数组长度为 10 时，可以扩展为 16，并将新添加的元素设置为中性元素（如 0）。\n",
    "- 数学意义：扩展操作确保算法可以使用标准的二叉树拓扑结构。\n",
    "\n",
    "---\n",
    "\n",
    "### 声明定制并行归约\n",
    "\n",
    "`#pragma omp declare reduction` 是 OpenMP 中用于自定义归约操作的语句。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0144f",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#pragma omp declare reduction (reduction-name: type: combiner-function) initializer(initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d215cb7",
   "metadata": {},
   "source": [
    "- **reduction-name**：为归约操作起一个名字（这只是用于在 OpenMP 并行区域内进行引用）。例如，可以是 `sum`, `min`, `max`，或者你自定义的名字。\n",
    "- **type**：定义了归约操作中使用的数据类型。例如，对于一个累加和归约操作，类型可能是 `int` 或 `double`。\n",
    "- **combiner-function**：是一个用户自定义的函数，它定义了如何将两个线程的结果合并起来,一般这个函数是结构体内的成员函数。这个函数必须是一个二元函数，即它接收两个输入，并返回合并后的结果。例如，累加操作的函数是 `a + b`，而乘法操作是 `a * b`。\n",
    "- **initializer**（可选）：这个函数用于在并行区域内为每个线程的归约变量设置初始值。通常，归约操作的初始值是中性元素，比如累加操作的初始值是 0，累乘操作的初始值是 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6bf89d",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>\n",
    "\\#include <cstdint>\n",
    "\\#include <cmath>\n",
    "\\#include <random>\n",
    "\\#include <immintrin.h> // AVX intrinsics\n",
    "struct avxop {\n",
    "    __m256 neutral;  // 一个 256 位的 AVX 寄存器\n",
    "\n",
    "    avxop() : neutral(_mm256_set1_ps(-INFINITY)) {}  // 构造函数初始化为 -INFINITY\n",
    "\n",
    "    __m256 operator() (const __m256& lhs, const __m256& rhs) const {\n",
    "        return _mm256_max_ps(lhs, rhs);  // 对应最大值操作\n",
    "    }\n",
    "};\n",
    "\n",
    "void init(float *data, uint64_t length) {\n",
    "    std::mt19937 engine(42);  // 使用 Mersenne Twister 随机数生成器\n",
    "    std::uniform_real_distribution<float> density(-1L<<28, 1L<<28);  // 均匀分布范围\n",
    "    for (uint64_t i = 0; i < length; i++)\n",
    "        data[i] = density(engine);  // 填充数据\n",
    "}\n",
    "\n",
    "inline float hmax_sse3(__m128 v) {\n",
    "    __m128 shuf = _mm_movehdup_ps(v);  // 复制高位到低位\n",
    "    __m128 maxs = _mm_max_ps(v, shuf);  // 计算最大值\n",
    "    shuf = _mm_movehl_ps(shuf, maxs);  // 高低交换\n",
    "    maxs = _mm_max_ss(maxs, shuf);  // 继续计算最大值\n",
    "    return _mm_cvtss_f32(maxs);  // 转换为浮点数\n",
    "}\n",
    "\n",
    "inline float hmax_avx(__m256 v) {\n",
    "    __m128 hi = _mm256_extractf128_ps(v, 1);  // 提取高位\n",
    "    __m128 lo = _mm256_castps256_ps128(v);  // 提取低位\n",
    "    lo = _mm_max_ps(lo, hi);  // 计算低位和高位的最大值\n",
    "    return hmax_sse3(lo);  // 使用 SSE3 计算最终的最大值\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const uint64_t num_entries = 1UL << 28;  // 设置数据长度为 2^28\n",
    "    const uint64_t num_bytes = num_entries * sizeof(float);  // 计算字节数\n",
    "    auto data = static_cast<float*>(_mm_malloc(num_bytes, 32));  // 分配内存，要求 32 字节对齐\n",
    "    init(data, num_entries);  // 填充数据\n",
    "\n",
    "    \\#pragma omp declare reduction(avxmax: __m256: omp_out = avxop() (omp_out, omp_in)) \\\n",
    "        initializer(omp_priv = avxop().neutral)\n",
    "    auto result = avxop().neutral;  // 初始化归约结果为中性元素\n",
    "\n",
    "    \\#pragma omp parallel for reduction(avxmax: result)  // 并行归约操作\n",
    "    for (uint64_t i = 0; i < num_entries; i += 8)\n",
    "        result = avxop()(result, _mm256_load_ps(data + i));  // 使用 AVX 加载数据并进行归约\n",
    "\n",
    "    std::cout << hmax_avx(result) << std::endl;  // 计算最终结果的最大值并输出\n",
    "    _mm_free(data);  // 释放内存\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595bcfbe",
   "metadata": {},
   "source": [
    "## openmp高级归约\n",
    "\n",
    "### 归约的总体执行流程\n",
    "\n",
    "1. **创建线程组，确定每个线程需要执行的迭代集合**\n",
    "\n",
    "- 在并行归约操作中，首先会创建一个线程组。每个线程负责计算某一部分的归约任务。通过合理的任务划分，可以保证每个线程的负载均衡，避免某些线程空闲，而其他线程过于繁忙。\n",
    "- 任务的分配可以通过不同的调度策略来实现，如静态、动态、引导（guided）等。\n",
    "\n",
    "2. **每个线程声明一个归约变量的私有化变量，初始化为幺半群的中性元素**\n",
    "\n",
    "- 每个线程都有一个私有的归约变量，通常是归约操作中的一个中间结果。例如，在求和操作中，私有化变量会初始化为 0；在求最大值操作中，则初始化为 `INFINITY` 或数据类型的最小值。\n",
    "- 这个私有化变量用来保存每个线程在其负责的迭代集合上的局部计算结果。\n",
    "\n",
    "3. **所有线程执行迭代，而不管它们是否或如何涉及私有化变量的更新**\n",
    "\n",
    "- 所有线程并行执行归约操作。每个线程根据其被分配的任务区间，独立计算归约变量的局部值。由于是并行计算，线程之间的操作是独立的，它们各自更新自己的私有化变量，而不直接干涉其他线程。\n",
    "- 在这一步骤中，线程只是计算局部结果，并未进行全局合并。\n",
    "\n",
    "4. **部分结果通过串行归约计算合并，并写回到全局变量**\n",
    "\n",
    "- 一旦所有线程完成了局部计算，接下来会通过串行归约将这些部分结果合并成最终结果。这个步骤通常是在最后一个线程执行完任务后，进行局部结果的合并。\n",
    "- 如果是二叉树结构的归约，多个局部结果将两两合并，直到最终得到全局结果。这个过程可以是递归的，也可以是通过循环实现。\n",
    "- 最后，最终的归约结果会被写回到全局变量，确保每个线程的局部计算结果得到了合并。\n",
    "\n",
    "---\n",
    "\n",
    "### 归约映射的可交换性\n",
    "\n",
    "归约操作的**可交换性**对于并行计算至关重要，它使得我们可以灵活地调整计算的顺序，并且保证最终结果的一致性。只有满足可交换性和结合性的操作才能在并行计算中得到正确的结果。对于不可交换的操作，我们需要确保操作顺序的合理性，以避免由于并行执行引发的错误。\n",
    "\n",
    "### 隐式屏障\n",
    "\n",
    "### 隐式屏障的局限性\n",
    "\n",
    "OpenMP的隐式屏障只保证在并行区域内所有线程完成任务后才退出，但它并不能保证在归约操作时，所有线程的局部结果都被正确地同步到全局变量 `x`。因此，如果使用并行归约时依赖于隐式屏障，可能会导致以下问题：\n",
    "\n",
    "- 局部归约结果未被正确更新到全局变量。\n",
    "- 由于线程的执行顺序和任务划分的不同，结果的不确定性会增加。\n",
    "\n",
    "# 任务并行\n",
    "\n",
    "## 树遍历\n",
    "\n",
    "### `#pragma omp task`\n",
    "\n",
    "`#pragma omp task` 是 OpenMP 中的一个并行化指令，用于将任务标记为可并行执行的部分。它的作用是将某段代码块指定为独立的任务，这些任务可以由多个线程并行执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53738af",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#pragma omp task [clause]\n",
    "{\n",
    "    // code to be executed as a task\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492a426",
   "metadata": {},
   "source": [
    "**作用**\n",
    "\n",
    "- 将任务放入任务队列，并等待线程池中的线程来执行这些任务。任务队列中的任务将会在可用线程上调度执行。\n",
    "- 每个任务在其所在的线程中独立执行，与其他任务之间没有数据依赖关系，除非通过共享变量显式地传递数据。\n",
    "\n",
    "**常见用途**\n",
    "\n",
    "- **递归**：在树结构的遍历中，子问题的解决可以通过并行任务来执行。\n",
    "- **分治算法**：将一个大问题分解为小任务，使用并行化加速处理。\n",
    "\n",
    "### 树节点遍历函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02ac97",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>\n",
    "\\#include <cstdint>\n",
    "\\#include <cmath>\n",
    "\\#include \"../include/hpc_helpers.hpp\"\n",
    "\\#define VALUE_T double\n",
    "\n",
    "template <typename value_t>\n",
    "class Node {\n",
    "public:\n",
    "    value_t value_;\n",
    "    Node<value_t>* left_;\n",
    "    Node<value_t>* right_;\n",
    "\n",
    "    Node() {}\n",
    "    Node(value_t value) : value_(value) {}\n",
    "    Node(value_t value, Node<value_t>* left, Node<value_t>* right)\n",
    "        : value_(value), left_(left), right_(right) {}\n",
    "\n",
    "    // In-order tree traversal, calling func with each value\n",
    "    void traverse(auto func, bool parallel=false) {\n",
    "        if (this->left_) {\n",
    "            \\#pragma omp task if (parallel)\n",
    "            this->left_->traverse(func, parallel);\n",
    "        }\n",
    "        func(this->value_);\n",
    "        if (this->right_) {\n",
    "            \\#pragma omp task if (parallel)\n",
    "            this->right_->traverse(func, parallel);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    void traverse() {\n",
    "        traverse([](auto &val) { std::cout << val << std::endl; });\n",
    "    }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6cba34",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\n",
    "int main() {\n",
    "    const uint64_t m = 15;\n",
    "    const uint64_t n = (1UL << m) - 1; // Total number of nodes\n",
    "    const uint64_t iterations = 1UL << 12; // Number of iterations within each task\n",
    "\n",
    "    TIMERSTART(overall)\n",
    "    TIMERSTART(alloc)\n",
    "    Node<VALUE_T> nodes[n];\n",
    "    TIMERSTOP(alloc)\n",
    "\n",
    "    TIMERSTART(init)\n",
    "    for (uint64_t i = (n-1); i > 0; --i) {\n",
    "        if (i > ((n / 2) - 1)) {\n",
    "            nodes[i] = Node<VALUE_T>(i);//叶子节点初始化\n",
    "        } else {\n",
    "            nodes[i] = Node<VALUE_T>(i, &nodes[2*i+1], &nodes[2*i+2]);//非叶子节点初始化,需要子节点的指针\n",
    "        }\n",
    "    }\n",
    "    Node<VALUE_T> tree(0, &nodes[1], &nodes[2]);//根节点\n",
    "    TIMERSTOP(init)\n",
    "\n",
    "    TIMERSTART(sum)\n",
    "    VALUE_T sum = 0;\n",
    "    tree.traverse([&](auto &val) { sum += val; });\n",
    "    std::cout << (n * (n - 1) / 2) << \" ?= \" << sum << std::endl;\n",
    "    TIMERSTOP(sum)\n",
    "\n",
    "    auto func = [](auto &val) {\n",
    "        for (uint64_t i = 0; i < iterations; ++i)\n",
    "            val = std::pow(val, 1.1);\n",
    "    };\n",
    "\n",
    "    TIMERSTART(sequential)\n",
    "    tree.traverse(func);\n",
    "    TIMERSTOP(sequential)\n",
    "\n",
    "    TIMERSTART(parallel)\n",
    "    \\#pragma omp parallel\n",
    "    {\n",
    "        \\#pragma omp single\n",
    "        {\n",
    "            \\#pragma omp task\n",
    "            tree.traverse(func, true);\n",
    "        }\n",
    "    }\n",
    "    TIMERSTOP(parallel)\n",
    "    TIMERSTOP(overall)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4924353",
   "metadata": {},
   "source": [
    "## 循环中生成任务\n",
    "\n",
    "`#pragma omp taskloop` 是 OpenMP 中的一种指令，用于并行化循环，并将循环迭代分配给不同的任务（task）。它与常规的 OpenMP 循环指令 `#pragma omp for` 的主要区别在于，`taskloop` 会将每个迭代作为独立的任务执行，而不是简单地将迭代分配给线程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2a01a",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#pragma omp taskloop [clause]\n",
    "for (int i = 0; i < N; i++) {\n",
    "    // loop body\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c4e1f",
   "metadata": {},
   "source": [
    "- `**grainsize**`：\n",
    "    - `grainsize` 用于控制任务的大小（即每个任务应执行的迭代数目）。通过设置合理的 `grainsize`，可以减少任务创建和调度的开销，同时避免任务过小带来的负担。它帮助平衡任务的分配，使得每个任务的工作量接近，并且不会因为任务过小而造成过多的调度开销。\n",
    "    - **示例**：`#pragma omp taskloop grainsize(5)` 表示每个任务包含 5 个迭代。\n",
    "- `**num_tasks**`：\n",
    "    - `num_tasks` 用于指定生成的任务的数量。在某些情况下，你可能希望控制生成的任务的数量而不是迭代的粒度。这有助于更好地管理任务调度，避免任务过多导致性能下降。\n",
    "    - **示例**：`#pragma omp taskloop num_tasks(100)` 表示创建 100 个任务。\n",
    "\n",
    "---\n",
    "\n",
    "# omp中启动simd向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e4c76",
   "metadata": {
    "language": "C++"
   },
   "outputs": [],
   "source": [
    "\\#include <iostream>\n",
    "\\#include <cstdint>\n",
    "\\#include <vector>\n",
    "// hpc_helpers contains the TIMERSTART and TIMERSTOP macros\n",
    "// and the template that disables implicit type initialization\n",
    "\\#include \"../include/hpc_helpers.hpp\"\n",
    "\n",
    "int main() {\n",
    "    // memory allocation for the three vectors x, y, and z\n",
    "    // with the no_init_t template as a wrapper for the actual type\n",
    "    TIMERSTART(alloc)\n",
    "    const uint64_t num_entries = 1UL << 30; // corrected left-shift operator\n",
    "    std::vector<no_init_t<uint64_t>> x(num_entries); // corrected type and variable name\n",
    "    std::vector<no_init_t<uint64_t>> y(num_entries); // corrected type and variable name\n",
    "    std::vector<no_init_t<uint64_t>> z(num_entries); // corrected type and variable name\n",
    "    TIMERSTOP(alloc)\n",
    "\n",
    "    // manually initialize the input vectors x and y\n",
    "    TIMERSTART(init)\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) { // corrected loop variable and typo\n",
    "        x[i] = i;\n",
    "        y[i] = num_entries - i;\n",
    "    }\n",
    "    TIMERSTOP(init)\n",
    "\n",
    "    // compute x + y = z sequentially\n",
    "    TIMERSTART(add_seq)\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i];\n",
    "    }\n",
    "    TIMERSTOP(add_seq)\n",
    "\n",
    "    // compute x + y = z vectorized\n",
    "    TIMERSTART(add_vec)\n",
    "    \\#pragma omp simd\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i]; // corrected index and syntax\n",
    "    }\n",
    "    TIMERSTOP(add_vec)\n",
    "\n",
    "    // compute x + y = z in parallel\n",
    "    TIMERSTART(add_par)\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i];\n",
    "    }\n",
    "    TIMERSTOP(add_par)\n",
    "\n",
    "    // compute x + y = z in parallel *and* vectorized\n",
    "    TIMERSTART(add)\n",
    "    \\#pragma omp parallel for simd\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        z[i] = x[i] + y[i];\n",
    "    }\n",
    "    TIMERSTOP(add)\n",
    "\n",
    "    // check if summation is correct\n",
    "    TIMERSTART(check)\n",
    "    \\#pragma omp parallel for\n",
    "    for (uint64_t i = 0; i < num_entries; i++) {\n",
    "        if (z[i] != num_entries) { // corrected check\n",
    "            std::cout << \"error at position \" << i << std::endl;\n",
    "        }\n",
    "    }\n",
    "    TIMERSTOP(check)\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f68365",
   "metadata": {},
   "source": [
    "## 数据依赖\n",
    "\n",
    "**1. 数据依赖的范围必须大于向量化块的大小**：\n",
    "\n",
    "- 向量化依赖于数据之间的距离，如果两个迭代之间的依赖关系过小（例如相邻的两个元素），则向量化可能无法成功。为了有效地向量化，依赖必须跨越多个数据块，这样才能确保每个数据块可以独立地进行处理。\n",
    "- 例如，如果你有一个包含许多数据元素的数组，且每个元素的计算需要依赖于距离较远的元素，那么你可以利用这一点来分配数据到向量寄存器中进行并行计算。\n",
    "\n",
    "可以使用safelen来指定安全长度.`#pragma omp simd safelen(L)`\n",
    "\n",
    "---\n",
    "\n",
    "[[并行程序设计]]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "language,-all",
   "main_language": "c++",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
